{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu00608/miniconda3/envs/lofi/lib/python3.6/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.framework.ops import disable_eager_execution \n",
    "from model import VariationalAutoEncoder\n",
    "disable_eager_execution()\n",
    "\n",
    "if not os.path.exists(\"result\"):\n",
    "    os.mkdir(\"result\")\n",
    "\n",
    "config = yaml.safe_load(open('config.yaml', 'r'))\n",
    "params = config['params']\n",
    "encoder_params = config['encoder']\n",
    "decoder_params = config['decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train.astype(np.float64) / 255.\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test.astype(np.float64) / 255.\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 200)\n",
      "3136\n",
      "(7, 7, 64)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 14, 14, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 14, 14, 32)   128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 14, 14, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 14, 14, 32)   0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 7, 7, 64)     18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 7, 7, 64)     36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 64)     256         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 200)          627400      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 200)          627400      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 200)          0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,311,184\n",
      "Trainable params: 1,310,864\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3136)              630336    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_t_1 (Conv2DTranspose)   (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_t_2 (Conv2DTranspose)   (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_t_3 (Conv2DTranspose)   (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 686,401\n",
      "Trainable params: 686,209\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = VariationalAutoEncoder(\n",
    "    input_shape=x_train[0].shape, \n",
    "    params=params, \n",
    "    encoder_params=encoder_params, \n",
    "    decoder_params=decoder_params)\n",
    "\n",
    "print(model.encoder.summary())\n",
    "print(model.decoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 32s 534us/sample - loss: 90.6530 - vae_loss: 90.6531 - r_loss: 84.8722 - kl_loss: 5.7807\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 27s 454us/sample - loss: 84.9686 - vae_loss: 84.9686 - r_loss: 84.8672 - kl_loss: 0.1014\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 27s 454us/sample - loss: 84.8863 - vae_loss: 84.8863 - r_loss: 84.8624 - kl_loss: 0.0239\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 27s 457us/sample - loss: 84.8638 - vae_loss: 84.8639 - r_loss: 84.8621 - kl_loss: 0.0018\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 27s 458us/sample - loss: 84.8661 - vae_loss: 84.8660 - r_loss: 84.8660 - kl_loss: 6.5001e-05\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 28s 466us/sample - loss: 84.8644 - vae_loss: 84.8645 - r_loss: 84.8645 - kl_loss: 2.5964e-06\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 28s 469us/sample - loss: 84.8656 - vae_loss: 84.8656 - r_loss: 84.8656 - kl_loss: 1.1812e-06\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 27s 457us/sample - loss: 84.8635 - vae_loss: 84.8635 - r_loss: 84.8635 - kl_loss: 1.1468e-06\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 28s 459us/sample - loss: 84.8665 - vae_loss: 84.8665 - r_loss: 84.8665 - kl_loss: 1.1331e-06\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 28s 461us/sample - loss: 84.8655 - vae_loss: 84.8655 - r_loss: 84.8655 - kl_loss: 1.1247e-06\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 28s 464us/sample - loss: 84.8635 - vae_loss: 84.8634 - r_loss: 84.8634 - kl_loss: 1.1196e-06\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 28s 473us/sample - loss: 84.8657 - vae_loss: 84.8658 - r_loss: 84.8658 - kl_loss: 1.1142e-06\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 27s 458us/sample - loss: 84.8670 - vae_loss: 84.8671 - r_loss: 84.8671 - kl_loss: 1.1103e-06\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 28s 461us/sample - loss: 84.8664 - vae_loss: 84.8664 - r_loss: 84.8664 - kl_loss: 1.1070e-06\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 28s 461us/sample - loss: 84.8612 - vae_loss: 84.8612 - r_loss: 84.8612 - kl_loss: 1.1026e-06\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 27s 458us/sample - loss: 84.8664 - vae_loss: 84.8664 - r_loss: 84.8664 - kl_loss: 1.1012e-06\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 28s 458us/sample - loss: 84.8688 - vae_loss: 84.8687 - r_loss: 84.8687 - kl_loss: 1.0993e-06\n",
      "Epoch 18/200\n",
      " 2336/60000 [>.............................] - ETA: 26s - loss: 84.7878 - vae_loss: 84.7878 - r_loss: 84.7878 - kl_loss: 1.0899e-06"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6a434d3e699c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repositories/ae-family/AutoEncoder/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             verbose=1)\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lofi/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/lofi/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/lofi/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lofi/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3956\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3957\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3959\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda3/envs/lofi/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(x_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('lofi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af42d6b00596c858df57cfb1e3d56019ad36764fdda4c39cb12fa72d6aaee7c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
